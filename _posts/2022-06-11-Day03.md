---
layout: single
title:  "Day1 : 팀 프로젝트 시작"
category: Project, Flask, Team
---

# ▶ 팀 프로젝트 3일차

팀프로젝트 3일차에 들어섰다. 어제 했던 LSTM으로 주가예측 하는것은 찾아보니<br>
컴퓨터에게 "28일의 주식가격 어떻게 될거같냐고" 물어보시면 "27일의 주식가격이랑 같습니다" 라고 답변한다는겁니다. 라는 결과를 얻었다. <br>
알고보니 딥러닝을 돌릴 때 loss 값을 최소화 하라고 시키고 <br>
loss 값은 (예측값 - 실제값)을 사용한다. <br>
loss가 가장 적은 예측 모델은
<b>"내일 주식가격은 오늘 주식가격과 똑같을 것이다.</b>라는 것이다. <br>
하지만 잘못되거나 그런건 아니다. 컴퓨터는 가장 loss가 적게나오는 효율적인 예측 모델을 만들었을 뿐이다......

내가 사용했던 코드는 다음과 같다.
```python
# 텐서플로우 케라스 패키지를 이용한 LSTM(LongTermShortTerm Memory)장단기기억 알고리즘을 이용한 주가예측 모델 
# 아래 예시는 LSTM 알고리즘을 사용해 훈련용 데이터는 70%, 테스트용 데이터는 30%를 사용해 실습
import tensorflow as tf # pip install tensorflow
from tensorflow.keras import Sequential 
from tensorflow.keras.layers import Dense,LSTM,Dropout
import numpy as np 
import matplotlib.pyplot as plt
import mplfinance as mdf
from pandas_datareader import data as pdr 
import pandas as pd
import yfinance as yf 
import matplotlib.pyplot as plt


data= pdr.get_data_yahoo('005930.KS',start='2020-01-03')
data.columns #Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')

df= pd.DataFrame( 
           {'Open':data['Open'],
            'High':data['High'],
            'Low':data['Low'],
            'Volume':data['Volume'],
            'Close':data['Close']
            })

def MinMaxScaler(data): 
    #최솟값과 최댓값을 이용하여 0~1값으로 반환 
    #OHLVC 데이터를 0~1사이 작은 단위로 변환해 계산소요시간을 단축한다. 0으로 나누기 에러가 발생하지 않도록 매우 작은 단위의 1e-7을 더해서 나눈다. 
    numerator = data - np.min(data,0)
    denominator = np.max(data,0)- np.min(data,0)
    return numerator/(denominator+ 1e-7)

dfx= MinMaxScaler(df)
dfy= dfx[['Close']]
x=dfx.values.tolist() # OHLVC를 tolist 함수를 이용해 하나의 리스트형태로 묶어줌 (최종:리스트의 리스트)
y=dfy.values.tolist() # Close(종가) 데이터만 리스트형태로 묶어줌 (최종:리스트의 리스트)
''' (dfx)-> 애플의 OHLVC 데이터를 0~1 사잇값으로 변환하였음  
Date	    Open	    High	    Low	        Volume	    Close				
2000-01-04	0.039426	0.035623	0.037207	0.451816	0.038292
2000-01-05	0.037147	0.035091	0.035599	0.454770	0.032287
2000-01-06	0.036577	0.032114	0.036288	0.331212	0.032740
(x)
[[0.039425706472151975, 0.03562313908971116, 0.03720716582448644, 0.45181621654538234, 0.0382916053018712],
...
...]
(y)
[[0.0382916053018712], 
[0.03228730032850086], 
[0.0327404554208307],
...
...]
'''
# 데이터셋 생성
data_x =[] 
data_y= []
window_size=7 #10일간의 OHLVC 데이터 
for i in range(len(y)-window_size):
    _x=x[i:i+window_size] #10일간의 OHLVC 데이터 
    _y=y[i+window_size]   #다음날의 종가 
    data_x.append(_x) 
    data_y.append(_y) 
# print(_x,"->",y) #10일간의 종가데이터 -> 10일 후의 종가 

# 훈련용 데이터셋 (70%)
train_size= int(len(data_y)*0.7) 
train_x= np.array(data_x[0:train_size]) 
train_y= np.array(data_y[0:train_size])
# 테스트 데이터셋 (30%) 
test_size= len(data_y)- train_size
test_x = np.array(data_x[train_size:len(data_x)])
test_y = np.array(data_y[train_size:len(data_y)])

# 딥러닝(LSTM) 모델생성
def model(window_size): 
    model = Sequential() 
    model.add(LSTM(units=10,activation='relu',return_sequences=True,input_shape=(window_size,5)))
    model.add(Dropout(0.1)) # Dropout을 10% 지정, 입력값의 일부분을 선택해서 그 값을 0으로 전환하여 다음층으로 출력해 훈련 데이터를 늘리지 않고도 과적합을 방지 
    model.add(LSTM(units=10,activation='relu'))
    model.add(Dropout(0.1)) 
    model.add(Dense(units=1)) #유닛이 1개인 출력층 추가
    model.summary() 

    model.compile(optimizer='adam',loss='mean_squared_error') #최적화 도구는 adam을 사용, 손실함수는 평균제곱오차(MSE) 사용 
    model.fit(train_x,train_y,epochs=60,batch_size=30) #훈련데이터셋 학습, epoch는 학습횟수, batch_size는 한번에 제공되는 훈련데이터 개수  
    pred_y= model.predict(test_x) 
    
    return pred_y

pred_y = model(window_size)
''' 
Epoch 횟수가 증가할 수록 손실함수의 결괏값(Loss)가 줄어든다. 
참고) 학습이란 훈련데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것을 말하는데 손실함수는 신경망이 학습할 수 있도록 하는 지표인데, 이 손실함수의 결과값을 가장 작게 만드는 것이 학습의 목표이다(0에 수렴하도록).
Epoch를 늘려도 Loss 가 더이상 줄지 않는 포인트가 있다(대략저인 적정 Epoch 갯수확인방법)
초기 df 추출과정에서 20년치를 뽑으면 Loss가 강하지만 2년치를 뽑으면(짧을 수록)정확도가 나름 높여진다.  
'''

import matplotlib.pyplot as plt 
plt.figure()
plt.plot(test_y, color='red', label='Real Apple Price') 
plt.plot(pred_y, color='blue',label='Predicted Apple Price') 
plt.title('Apple Prediction') 
plt.xlabel('time')
plt.ylabel('stockprice') 
plt.legend() 
plt.show() 

#다음날 예측종가 출력 
print("Tomorrow price:",df.Close[-1]*pred_y[-1]/dfy.Close[-1]) 
#종가 예측치 pred_y[-1]은 부동소수형임으로 변환전 마지막날의 종가(df.Close[-1])와 
#변환후의 마지막날 종가(dfy.close[-1])의 관계식을(df.close[-1]:dfy.close[-1])=y:pred) 이용해 내일의 예측가격 y를 구한다.

```

이 코드를 사용하려면 다른 관점으로 다양하게 시도해봐야 할 것같다.

SVM 방식으로 주식 예측도 있는데 그것도 한번 시도 해볼것이다.


# ▶ 오늘의 메모
컴퓨터한테 예측해서 결과값을 도출한 값이 실제로 맞아 떨어질수 없다는 것을 알면서도 사람의 심리라는게 의심은 하지만 컴퓨터를 믿고있다. <br>
하지만 이런 코드들을 짜면서 정보도 많이 얻고 나의 코딩실력이 늘고있는 것을 느끼고 있다. 도서관에서 책도 빌리고 교보문고가서 책들도 찾아봄으로서 영감을 점점 얻어가고있다.😁😁
